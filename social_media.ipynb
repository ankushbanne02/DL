{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b67951",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Embedding, LSTM,Dropout,Dense\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39467ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Time of Tweet</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>morning</td>\n",
       "      <td>What a great day!!! Looks like dream.</td>\n",
       "      <td>positive</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>noon</td>\n",
       "      <td>I feel sorry, I miss you here in the sea beach</td>\n",
       "      <td>positive</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>night</td>\n",
       "      <td>Don't angry me</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>morning</td>\n",
       "      <td>We attend in the class just for listening teac...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>noon</td>\n",
       "      <td>Those who want to go, let them go</td>\n",
       "      <td>negative</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>night</td>\n",
       "      <td>According to , a quarter of families under six...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2021</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>morning</td>\n",
       "      <td>the plan to not spend money is not going well</td>\n",
       "      <td>negative</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>2022</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>noon</td>\n",
       "      <td>uploading all my bamboozle pictures of facebook</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2018</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>night</td>\n",
       "      <td>congratulations ! you guys finish a month ear...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>morning</td>\n",
       "      <td>actually, I wish I was back in Tahoe.  I miss...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Month  Day Time of Tweet  \\\n",
       "0    2018      8   18       morning   \n",
       "1    2018      8   18          noon   \n",
       "2    2017      8   18         night   \n",
       "3    2022      6    8       morning   \n",
       "4    2022      6    8          noon   \n",
       "..    ...    ...  ...           ...   \n",
       "494  2015     10   18         night   \n",
       "495  2021      2   25       morning   \n",
       "496  2022      5   30          noon   \n",
       "497  2018      8   10         night   \n",
       "498  2019      3   25       morning   \n",
       "\n",
       "                                                  text sentiment     Platform  \n",
       "0                What a great day!!! Looks like dream.  positive    Twitter    \n",
       "1       I feel sorry, I miss you here in the sea beach  positive    Facebook   \n",
       "2                                       Don't angry me  negative     Facebook  \n",
       "3    We attend in the class just for listening teac...  negative    Facebook   \n",
       "4                    Those who want to go, let them go  negative   Instagram   \n",
       "..                                                 ...       ...          ...  \n",
       "494  According to , a quarter of families under six...  negative     Twitter   \n",
       "495      the plan to not spend money is not going well  negative   Instagram   \n",
       "496    uploading all my bamboozle pictures of facebook   neutral    Facebook   \n",
       "497   congratulations ! you guys finish a month ear...  positive     Twitter   \n",
       "498   actually, I wish I was back in Tahoe.  I miss...  negative   Instagram   \n",
       "\n",
       "[499 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('C:/Users/AKASH/Desktop/sentiment_analysis.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c78458f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= data['text']\n",
    "y=data['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce01ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= np.array([1 if label=='positive' else 0 for label in y])\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "beb9d70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text=re.sub('[^a-zA-Z]',' ',text)\n",
    "    text=text.lower().strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75862382",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[preprocess_text(sentence) for sentence in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193181ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_token=200\n",
    "vocb_size=15000\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(vocb_size)\n",
    "tokenizer.fit_on_texts(x)\n",
    "x_tokens= tokenizer.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adb0f086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  32,   5,\n",
       "        95,  16, 107,  33, 397])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_pad = tf.keras.preprocessing.sequence.pad_sequences(x_tokens,max_token)\n",
    "x_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0809e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test =train_test_split(x_pad,y,test_size=0.3,random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a65ff8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 50)           750000    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 16)           4288      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 16)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 200, 8)            800       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200, 8)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 200, 4)            208       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 200, 4)            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 2)                 56        \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2)                 0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 755355 (2.88 MB)\n",
      "Trainable params: 755355 (2.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= keras.models.Sequential()\n",
    "\n",
    "embedding=50\n",
    "model.add(Embedding(input_dim=vocb_size,output_dim=embedding,input_length=max_token))\n",
    "\n",
    "model.add(LSTM(units=16,return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(units=8,return_sequences=True))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(LSTM(units=4,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fed67ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt= tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f13fd29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.6947 - accuracy: 0.3954 - val_loss: 0.6909 - val_accuracy: 0.6733\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6912 - accuracy: 0.6418 - val_loss: 0.6874 - val_accuracy: 0.6800\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.6877 - accuracy: 0.6619 - val_loss: 0.6838 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16133fbf310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,validation_data=(x_test,y_test), batch_size=1024, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75007bfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 70ms/step - loss: 0.6838 - accuracy: 0.6800\n",
      "Accuracy: 0.6800000071525574\n",
      "LOSS: 0.6838192939758301\n"
     ]
    }
   ],
   "source": [
    "hist=model.evaluate(x_test,y_test)\n",
    "print(\"Accuracy:\",hist[1])\n",
    "print(\"LOSS:\", hist[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "632ccd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter reviewWhat a great day!!! Looks like dream.\t\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "NEGATIVE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sentence= input(\"Enter review\")\n",
    "tokenizer.fit_on_texts(sentence)\n",
    "x1_tokens= tokenizer.texts_to_sequences([sentence])\n",
    "x_pad1 = tf.keras.preprocessing.sequence.pad_sequences(x1_tokens,max_token)\n",
    "    \n",
    "predict=model.predict(x_pad1)\n",
    "if predict>=0.5:\n",
    "    print(\"POSITIVE\")\n",
    "        \n",
    "else:\n",
    "     print(\"NEGATIVE\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b9c653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
